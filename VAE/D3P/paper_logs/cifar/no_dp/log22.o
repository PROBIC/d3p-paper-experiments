Epoch 0: loss = 2121.86962890625 (on training set: 2122.023193359375) (11.15 s.)
Epoch 1: loss = 2038.6026611328125 (on training set: 2098.289794921875) (1.64 s.)
Epoch 2: loss = 1989.9676513671875 (on training set: 2011.9442138671875) (1.64 s.)
Epoch 3: loss = 1956.5831298828125 (on training set: 1971.015380859375) (1.64 s.)
Epoch 4: loss = 1945.6868896484375 (on training set: 1948.2357177734375) (1.63 s.)
Epoch 5: loss = 1935.812255859375 (on training set: 1938.88134765625) (1.64 s.)
Epoch 6: loss = 1929.621826171875 (on training set: 1930.473388671875) (1.64 s.)
Epoch 7: loss = 1921.7271728515625 (on training set: 1926.0750732421875) (1.64 s.)
Epoch 8: loss = 1922.05322265625 (on training set: 1922.6717529296875) (1.64 s.)
Epoch 9: loss = 1920.6868896484375 (on training set: 1918.8287353515625) (1.64 s.)
Epoch 10: loss = 1916.5506591796875 (on training set: 1914.4649658203125) (1.64 s.)
Epoch 11: loss = 1913.7918701171875 (on training set: 1911.51806640625) (1.64 s.)
Epoch 12: loss = 1912.6429443359375 (on training set: 1912.3306884765625) (1.64 s.)
Epoch 13: loss = 1911.6431884765625 (on training set: 1910.8731689453125) (1.65 s.)
Epoch 14: loss = 1911.5142822265625 (on training set: 1908.7603759765625) (1.63 s.)
Epoch 15: loss = 1908.0908203125 (on training set: 1904.97705078125) (1.64 s.)
Epoch 16: loss = 1906.4217529296875 (on training set: 1903.248046875) (1.64 s.)
Epoch 17: loss = 1904.92236328125 (on training set: 1901.8023681640625) (1.64 s.)
Epoch 18: loss = 1905.6627197265625 (on training set: 1903.1568603515625) (1.64 s.)
Epoch 19: loss = 1902.7183837890625 (on training set: 1899.9417724609375) (1.64 s.)
