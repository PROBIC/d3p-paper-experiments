epsilon: 0.5355521751768667
Epoch 0: loss = 386.4875793457031 (on training set: 394.7807922363281) (5.88 s.)
Epoch 1: loss = 386.1738586425781 (on training set: 386.170166015625) (0.55 s.)
Epoch 2: loss = 379.666748046875 (on training set: 383.07464599609375) (0.55 s.)
Epoch 3: loss = 350.5423583984375 (on training set: 364.00360107421875) (0.55 s.)
Epoch 4: loss = 329.0280456542969 (on training set: 338.63067626953125) (0.55 s.)
Epoch 5: loss = 319.3712158203125 (on training set: 322.43255615234375) (0.56 s.)
Epoch 6: loss = 317.8948669433594 (on training set: 317.68304443359375) (0.55 s.)
Epoch 7: loss = 316.3590393066406 (on training set: 315.55877685546875) (0.55 s.)
Epoch 8: loss = 315.56915283203125 (on training set: 315.0139465332031) (0.55 s.)
Epoch 9: loss = 313.7469177246094 (on training set: 314.3270568847656) (0.55 s.)
Epoch 10: loss = 313.34088134765625 (on training set: 312.7952880859375) (0.55 s.)
Epoch 11: loss = 312.43365478515625 (on training set: 311.8857116699219) (0.55 s.)
Epoch 12: loss = 310.295166015625 (on training set: 310.9821472167969) (0.55 s.)
Epoch 13: loss = 309.64764404296875 (on training set: 309.15692138671875) (0.55 s.)
Epoch 14: loss = 308.41058349609375 (on training set: 307.51300048828125) (0.55 s.)
Epoch 15: loss = 309.03656005859375 (on training set: 307.11993408203125) (0.55 s.)
Epoch 16: loss = 306.3249816894531 (on training set: 306.076171875) (0.55 s.)
Epoch 17: loss = 306.45068359375 (on training set: 304.645751953125) (0.55 s.)
Epoch 18: loss = 304.6793518066406 (on training set: 304.3849182128906) (0.55 s.)
Epoch 19: loss = 304.3354797363281 (on training set: 303.93121337890625) (0.55 s.)
