epsilon: 0.5355521751768667
Epoch 0: loss = 386.66796875 (on training set: 394.7274475097656) (6.03 s.)
Epoch 1: loss = 386.3609924316406 (on training set: 385.45806884765625) (0.55 s.)
Epoch 2: loss = 381.0503234863281 (on training set: 384.54266357421875) (0.54 s.)
Epoch 3: loss = 355.09490966796875 (on training set: 367.2108459472656) (0.55 s.)
Epoch 4: loss = 335.0495910644531 (on training set: 344.33697509765625) (0.55 s.)
Epoch 5: loss = 322.4094543457031 (on training set: 325.5484619140625) (0.55 s.)
Epoch 6: loss = 319.1678161621094 (on training set: 319.60107421875) (0.55 s.)
Epoch 7: loss = 317.70977783203125 (on training set: 316.64117431640625) (0.55 s.)
Epoch 8: loss = 316.6302490234375 (on training set: 315.6692810058594) (0.55 s.)
Epoch 9: loss = 315.6471252441406 (on training set: 315.25958251953125) (0.55 s.)
Epoch 10: loss = 316.10821533203125 (on training set: 314.6817626953125) (0.54 s.)
Epoch 11: loss = 314.430908203125 (on training set: 313.9482116699219) (0.55 s.)
Epoch 12: loss = 312.923828125 (on training set: 311.79412841796875) (0.55 s.)
Epoch 13: loss = 312.4881286621094 (on training set: 310.9943542480469) (0.55 s.)
Epoch 14: loss = 310.3619384765625 (on training set: 309.8722839355469) (0.55 s.)
Epoch 15: loss = 308.9488525390625 (on training set: 308.65228271484375) (0.55 s.)
Epoch 16: loss = 307.4986877441406 (on training set: 307.58038330078125) (0.55 s.)
Epoch 17: loss = 307.3517761230469 (on training set: 306.48175048828125) (0.55 s.)
Epoch 18: loss = 306.677734375 (on training set: 305.63531494140625) (0.55 s.)
Epoch 19: loss = 305.8239440917969 (on training set: 305.2049560546875) (0.54 s.)
